{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 512, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = torch.rand(5, 256, 512*2)\n",
    "projected_k = nn.Conv1d(512*2, 512, 1, 1)\n",
    "projected_k(keys.permute(1, 2, 0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted probabilities to a tensor of shape `(batch_size, num_classes)`.\n",
    "predicted_probabilities = torch.tensor([[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                                      [0.2, 0.3, 0.4, 0.5, 0.6]])\n",
    "\n",
    "# Take the index of the maximum probability in each row of the predicted probabilities tensor.\n",
    "true_labels = torch.argmax(predicted_probabilities, dim=1)\n",
    "\n",
    "# Convert the true labels to a tensor of shape `(batch_size)`.\n",
    "true_labels = true_labels.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `torch.nn.NLLLoss` object.\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "\n",
    "# Convert the predicted probabilities to a tensor of shape `(batch_size, num_classes)`.\n",
    "predicted_probabilities = torch.tensor([[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                                      [0.2, 0.3, 0.4, 0.5, 0.6]])\n",
    "\n",
    "# Convert the true labels to a tensor of shape `(batch_size)`.\n",
    "true_labels = torch.tensor([1, 3])\n",
    "\n",
    "# Calculate the loss using the `torch.nn.NLLLoss` object.\n",
    "loss = loss_fn(predicted_probabilities, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Pytorch implementation of Pointer-Net\")\n",
    "\n",
    "# Data\n",
    "parser.add_argument('--train_size', default=10000, type=int, help='Training data size')\n",
    "parser.add_argument('--val_size', default=1000, type=int, help='Validation data size')\n",
    "parser.add_argument('--test_size', default=1000, type=int, help='Test data size')\n",
    "parser.add_argument('--batch_size', default=256, type=int, help='Batch size')\n",
    "# Train\n",
    "parser.add_argument('--nof_epoch', default=5, type=int, help='Number of epochs')\n",
    "parser.add_argument('--lr', type=float, default=0.00001, help='Learning rate')\n",
    "# GPU\n",
    "parser.add_argument('--gpu', default=True, action='store_true', help='Enable gpu')\n",
    "# TSP\n",
    "parser.add_argument('--nof_points', type=int, default=5, help='Number of points in TSP')\n",
    "# Network\n",
    "parser.add_argument('--embedding_size', type=int, default=128, help='Embedding size')\n",
    "parser.add_argument('--hidden_size', type=int, default=512, help='Number of hidden units')\n",
    "parser.add_argument('--nof_lstms', type=int, default=2, help='Number of LSTM layers')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='Dropout value')\n",
    "parser.add_argument('--bidir', default=True, action='store_true', help='Bidirectional')\n",
    "\n",
    "params, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA GENERATOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsp_opt(points):\n",
    "    \"\"\"\n",
    "    Dynamic programing solution for TSP - O(2^n*n^2)\n",
    "    https://gist.github.com/mlalevic/6222750\n",
    "\n",
    "    :param points: List of (x, y) points\n",
    "    :return: Optimal solution\n",
    "    \"\"\"\n",
    "\n",
    "    def length(x_coord, y_coord):\n",
    "        return np.linalg.norm(np.asarray(x_coord) - np.asarray(y_coord))\n",
    "\n",
    "    # Calculate all lengths\n",
    "    all_distances = [[length(x, y) for y in points] for x in points]\n",
    "    # Initial value - just distance from 0 to every other point + keep the track of edges\n",
    "    A = {(frozenset([0, idx+1]), idx+1): (dist, [0, idx+1]) for idx, dist in enumerate(all_distances[0][1:])}\n",
    "    cnt = len(points)\n",
    "    for m in range(2, cnt):\n",
    "        B = {}\n",
    "        for S in [frozenset(C) | {0} for C in itertools.combinations(range(1, cnt), m)]:\n",
    "            for j in S - {0}:\n",
    "                # This will use 0th index of tuple for ordering, the same as if key=itemgetter(0) used\n",
    "                B[(S, j)] = min([(A[(S-{j}, k)][0] + all_distances[k][j], A[(S-{j}, k)][1] + [j])\n",
    "                                 for k in S if k != 0 and k != j])\n",
    "        A = B\n",
    "    res = min([(A[d][0] + all_distances[0][d[1]], A[d][1]) for d in iter(A)])\n",
    "    return np.asarray(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_distances - [[0.0, 5.0, 2.23606797749979, 2.23606797749979], [5.0, 0.0, 2.8284271247461903, 3.1622776601683795], [2.23606797749979, 2.8284271247461903, 0.0, 1.4142135623730951], [2.23606797749979, 3.1622776601683795, 1.4142135623730951, 0.0]]\n",
      "idx, dist - (0, 5.0)\n",
      "idx, dist - (1, 2.23606797749979)\n",
      "idx, dist - (2, 2.23606797749979)\n",
      "A - {(frozenset({0, 1}), 1): (5.0, [0, 1]), (frozenset({0, 2}), 2): (2.23606797749979, [0, 2]), (frozenset({0, 3}), 3): (2.23606797749979, [0, 3])}\n",
      "S - frozenset({0, 1, 2})\n",
      "(5.06449510224598, [0, 2, 1])\n",
      "(7.82842712474619, [0, 1, 2])\n",
      "S - frozenset({0, 1, 3})\n",
      "(5.39834563766817, [0, 3, 1])\n",
      "(8.16227766016838, [0, 1, 3])\n",
      "S - frozenset({0, 2, 3})\n",
      "(3.6502815398728847, [0, 3, 2])\n",
      "(3.6502815398728847, [0, 2, 3])\n",
      "S - frozenset({0, 1, 2, 3})\n",
      "(6.4787086646190755, [0, 3, 2, 1])\n",
      "(8.22677276241436, [0, 3, 1, 2])\n",
      "(8.22677276241436, [0, 2, 1, 3])\n",
      "result - [0 2 1 3]\n"
     ]
    }
   ],
   "source": [
    "def length(x_coord, y_coord):\n",
    "    return np.linalg.norm(np.asarray(x_coord) - np.asarray(y_coord))\n",
    "\n",
    "points = [(0,3), (4,0), (2,2), (1,1)]\n",
    "all_distances = [[length(x, y) for y in points] for x in points]\n",
    "print('all_distances -', all_distances)\n",
    "\n",
    "for idx, dist, in enumerate(all_distances[0][1:]):\n",
    "    print('idx, dist -', (idx, dist))\n",
    "\n",
    "A = {(frozenset([0, idx+1]), idx+1): (dist, [0, idx+1]) for idx, dist in enumerate(all_distances[0][1:])}\n",
    "print('A -', A)\n",
    "\n",
    "cnt = len(points)\n",
    "for m in range(2, cnt):\n",
    "    B = {}\n",
    "    for S in [frozenset(C) | {0} for C in itertools.combinations(range(1, cnt), m)]:\n",
    "        print('S -', S)\n",
    "        for j in S - {0}:\n",
    "            B[(S, j)] = min([(A[(S-{j}, k)][0] + all_distances[k][j], A[(S-{j}, k)][1] + [j]) for k in S if k != 0 and k != j])\n",
    "            print(B[(S, j)])\n",
    "    A = B\n",
    "res = min([(A[d][0] + all_distances[0][d[1]], A[d][1]) for d in iter(A)])\n",
    "print('result -', np.asarray(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5488135039273248, 0.3450895789457291),\n",
       " (0.417022004702574, 0.9512867249982255),\n",
       " (0.43599490214200376, 0.7226542571564433),\n",
       " (0.5507979025745755, 0.7452819903836411),\n",
       " (0.9670298390136767, 0.17371858915349359),\n",
       " (0.22199317108973948, 0.43601566470464426),\n",
       " (0.8928601514360016, 0.6696328241771722),\n",
       " (0.07630828937395717, 0.04175597567215328),\n",
       " (0.8734294027918162, 0.19354372191863545),\n",
       " (0.010374153885699955, 0.8233890742543671)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 10\n",
    "X = [np.random.RandomState(seed = i).random() for i in range (0, max_len)]\n",
    "Y = [np.random.RandomState(seed = i).random() for i in range (10000-max_len, 10000)]\n",
    "points = [(x, y) for x, y in zip(X, Y)]\n",
    "points"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "tsp_opt(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSPDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Random TSP dataset\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_size, seq_len, solver=tsp_opt, solve=True):\n",
    "        self.data_size = data_size\n",
    "        self.seq_len = seq_len\n",
    "        self.solve = solve\n",
    "        self.solver = solver\n",
    "        self.data = self._generate_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.from_numpy(self.data['Points_List'][idx]).float()\n",
    "        solution = torch.from_numpy(self.data['Solutions'][idx]).long() if self.solve else None\n",
    "\n",
    "        sample = {'Points':tensor, 'Solution':solution}\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def _generate_data(self):\n",
    "        \"\"\"\n",
    "        :return: Set of points_list ans their One-Hot vector solutions\n",
    "        \"\"\"\n",
    "        points_list = []\n",
    "        solutions = []\n",
    "        data_iter = tqdm(range(self.data_size), unit='data')\n",
    "        for i, _ in enumerate(data_iter):\n",
    "            data_iter.set_description('Data points %i/%i' % (i+1, self.data_size))\n",
    "            points_list.append(np.random.random((self.seq_len, 2)))\n",
    "        solutions_iter = tqdm(points_list, unit='solve')\n",
    "        if self.solve:\n",
    "            for i, points in enumerate(solutions_iter):\n",
    "                solutions_iter.set_description('Solved %i/%i' % (i+1, len(points_list)))\n",
    "                solutions.append(self.solver(points))\n",
    "        else:\n",
    "            solutions = None\n",
    "\n",
    "        return {'Points_List':points_list, 'Solutions':solutions}\n",
    "\n",
    "    def _to1hotvec(self, points):\n",
    "        \"\"\"\n",
    "        :param points: List of integers representing the points indexes\n",
    "        :return: Matrix of One-Hot vectors\n",
    "        \"\"\"\n",
    "        vec = np.zeros((len(points), self.seq_len))\n",
    "        for i, v in enumerate(vec):\n",
    "            v[points[i]] = 1\n",
    "\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data points 1000/1000: 100%|██████████| 1000/1000 [00:00<00:00, 2022.51data/s]\n",
      "Solved 1000/1000: 100%|██████████| 1000/1000 [00:00<00:00, 1404.98solve/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Points': tensor([[0.5211, 0.1678],\n",
       "         [0.8013, 0.2398],\n",
       "         [0.8029, 0.0372],\n",
       "         [0.0552, 0.8748],\n",
       "         [0.6464, 0.6626]]),\n",
       " 'Solution': tensor([0, 2, 1, 4, 3])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TSPDataset(data_size = 1000, seq_len = 5)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 64,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 881.32Batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([40, 5, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iterator = tqdm(dataloader, unit='Batch')\n",
    "for i, batched in enumerate(iterator):\n",
    "    print(batched['Points'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENCODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(train_size=10000, val_size=1000, test_size=1000, batch_size=256, nof_epoch=5, lr=1e-05, gpu=True, nof_points=5, embedding_size=128, hidden_size=512, nof_lstms=2, dropout=0.0, bidir=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x embed - torch.Size([5, 64, 128])\n",
      "h0- torch.Size([4, 64, 512])\n",
      "en_o - torch.Size([5, 64, 1024])\n",
      "en_h - torch.Size([4, 64, 512])\n",
      "en_c - torch.Size([4, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(64, 5, 2)\n",
    "embedding = nn.Linear(2, params.embedding_size)\n",
    "x_embed = embedding(x).permute(1, 0, 2)\n",
    "print('x embed -', x_embed.shape)\n",
    "\n",
    "lstm = nn.LSTM(\n",
    "    input_size = params.embedding_size,\n",
    "    hidden_size = params.hidden_size,\n",
    "    num_layers = params.nof_lstms,\n",
    "    bias = False,\n",
    "    batch_first = False,\n",
    "    dropout = params.dropout,\n",
    "    bidirectional = params.bidir\n",
    ")\n",
    "\n",
    "h0 = Parameter(torch.zeros(1), requires_grad=False).unsqueeze(0).unsqueeze(0).repeat(\n",
    "    2*params.nof_lstms, 64, params.hidden_size\n",
    ")\n",
    "c0 = Parameter(torch.zeros(1), requires_grad=False).unsqueeze(0).unsqueeze(0).repeat(\n",
    "    2*params.nof_lstms, 64, params.hidden_size\n",
    ")\n",
    "print('h0-', h0.shape)\n",
    "\n",
    "en_o, (en_h, en_c) = lstm(x_embed, (h0, c0))\n",
    "print('en_o -', en_o.shape)\n",
    "print('en_h -', en_h.shape)\n",
    "print('en_c -', en_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder class for Pointer-Net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, embedding_dim,\n",
    "        hidden_dim,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        bidir\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initiate Encoder\n",
    "\n",
    "        :param Tensor embedding_dim: Number of embbeding channels\n",
    "        :param int hidden_dim: Number of hidden units for the LSTM\n",
    "        :param int n_layers: Number of layers for LSTMs\n",
    "        :param float dropout: Float between 0-1\n",
    "        :param bool bidir: Bidirectional\n",
    "        \"\"\"\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers*2 if bidir else n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = embedding_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = n_layers,\n",
    "            bias = False,\n",
    "            batch_first = False,\n",
    "            dropout = dropout,\n",
    "            bidirectional = bidir\n",
    "        )\n",
    "\n",
    "        # Used for propagating .cuda() command\n",
    "        self.h0 = Parameter(torch.zeros(1), requires_grad = False)\n",
    "        self.c0 = Parameter(torch.zeros(1), requires_grad = False)\n",
    "\n",
    "    def forward(self, embedded_inputs, hidden):\n",
    "        \"\"\"\n",
    "        Encoder - Forward-pass\n",
    "\n",
    "        :param Tensor embedded_inputs: Embedded inputs of Pointer-Net\n",
    "        :param Tensor hidden: Initiated hidden units for the LSTMs (h, c)\n",
    "        :return: LSTMs outputs and hidden units (h, c)\n",
    "        \"\"\"\n",
    "        embedded_inputs = embedded_inputs.permute(1, 0, 2)\n",
    "\n",
    "        outputs, hidden = self.lstm(embedded_inputs, hidden)\n",
    "\n",
    "        return outputs.permute(1, 0, 2), hidden\n",
    "\n",
    "    def init_hidden(self, embedded_inputs):\n",
    "        \"\"\"\n",
    "        Initiate hidden units\n",
    "\n",
    "        :param Tensor embedded_inputs: The embedded input of Pointer-NEt\n",
    "        :return: Initiated hidden units for the LSTMs (h, c)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = embedded_inputs.shape[0]\n",
    "\n",
    "        # Reshaping (Expanding)\n",
    "        h0 = self.h0.unsqueeze(0).unsqueeze(0).repeat(self.n_layers, batch_size, self.hidden_dim)\n",
    "        c0 = self.h0.unsqueeze(0).unsqueeze(0).repeat(self.n_layers, batch_size, self.hidden_dim)\n",
    "\n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(256, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_o - torch.Size([256, 5, 1024])\n",
      "en_h - torch.Size([4, 256, 512])\n",
      "en_c - torch.Size([4, 256, 512])\n"
     ]
    }
   ],
   "source": [
    "x_embed = nn.Linear(2, params.embedding_size)(x)\n",
    "\n",
    "encoder = Encoder(\n",
    "    embedding_dim = params.embedding_size,\n",
    "    hidden_dim = params.hidden_size,\n",
    "    n_layers = params.nof_lstms,\n",
    "    dropout = params.dropout,\n",
    "    bidir = params.bidir\n",
    ")\n",
    "\n",
    "en_o, (en_h, en_c) = encoder(x_embed, encoder.init_hidden(x_embed))\n",
    "print('en_o -', en_o.shape)\n",
    "print('en_h -', en_h.shape)\n",
    "print('en_c -', en_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention model for Pointer-Net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, q_dim, k_dim, hidden_dim):\n",
    "        \"\"\"\n",
    "        Initiate Attention\n",
    "\n",
    "        :param int input_dim: Input's diamention\n",
    "        :param int hidden_dim: Number of hidden units in the attention\n",
    "        \"\"\"\n",
    "\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.q_dim = q_dim\n",
    "        self.k_dim = k_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.project_queries = nn.Linear(q_dim, hidden_dim, bias = False)\n",
    "        self.project_keys = nn.Linear(k_dim, hidden_dim, bias = False)\n",
    "        self.V = nn.Linear(hidden_dim, 1, bias = False)\n",
    "        self._inf = Parameter(torch.FloatTensor([float('-inf')]), requires_grad = False)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, queries, keys, mask):\n",
    "        \"\"\"\n",
    "        Attention - Forward-pass\n",
    "\n",
    "        :param Tensor queries: hidden state of decoder from step function in Decoder object (batch, hidden_dim)\n",
    "        :param Tensor keys: encoder outputs, or context (seq_len, batch, 2*hidden_dim)\n",
    "        :param ByteTensor mask: Selection mask\n",
    "        :return: tuple of - (Attentioned hidden state, Alphas)\n",
    "        \"\"\"\n",
    "        # Initialize -inf mask\n",
    "        self.inf = self._inf.unsqueeze(1).expand(mask.size())\n",
    "\n",
    "        # (batch, hidden_dim)\n",
    "        projected_q = self.project_queries(queries)\n",
    "        # (seq_len, batch, hidden_dim)\n",
    "        projected_k = self.project_keys(keys)\n",
    "        \n",
    "        # (batch, seq_len)\n",
    "        attention_pointer = self.V(self.tanh(projected_q + projected_k)).squeeze(-1).permute(-1, 0)\n",
    "        # if len(attention_pointer[mask]) > 0:\n",
    "        #     attention_pointer[mask] = self.inf[mask]\n",
    "        alpha = self.softmax(attention_pointer)\n",
    "\n",
    "        hidden_state = torch.bmm(projected_k.permute(1, 2, 0), alpha.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return hidden_state, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_de_h - torch.Size([256, 512])\n",
      "alpha - torch.Size([256, 5])\n",
      "tensor([0.1857, 0.1927, 0.2253, 0.1916, 0.2047], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A = Attention(\n",
    "    q_dim = 512, \n",
    "    k_dim = 512*2,\n",
    "    hidden_dim = 512\n",
    ")\n",
    "\n",
    "mask = Parameter(torch.ones(1), requires_grad=False).repeat(5).unsqueeze(0).repeat(256, 1)\n",
    "\n",
    "att_de_h, alpha = A(\n",
    "    queries = torch.rand(256, 512),\n",
    "    keys = torch.rand(5, 256, 512*2),\n",
    "    mask = torch.eq(mask, 0).type(torch.bool)\n",
    ")\n",
    "print('att_de_h -', att_de_h.shape)\n",
    "print('alpha -', alpha.shape)\n",
    "print(alpha[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DECODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder model for Pointer-Net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim,\n",
    "                 hidden_dim):\n",
    "        \"\"\"\n",
    "        Initiate Decoder\n",
    "\n",
    "        :param int embedding_dim: Number of embeddings in Pointer-Net\n",
    "        :param int hidden_dim: Number of hidden units for the decoder's RNN\n",
    "        \"\"\"\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.input_to_hidden = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "        self.hidden_to_hidden = nn.Linear(hidden_dim, 4 * hidden_dim)\n",
    "        self.hidden_out = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.att = Attention(q_dim = hidden_dim, k_dim = 2 * hidden_dim, hidden_dim = hidden_dim)\n",
    "\n",
    "        # Used for propagating .cuda() command\n",
    "        self.mask = Parameter(torch.ones(1), requires_grad = False)\n",
    "        self.runner = Parameter(torch.zeros(1), requires_grad = False)\n",
    "        self.index0 = Parameter(torch.zeros(1), requires_grad = False)\n",
    "\n",
    "    def forward(\n",
    "        self, embedded_inputs,\n",
    "        decoder_input,\n",
    "        hidden,\n",
    "        context, \n",
    "        beam_size\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Decoder - Forward-pass\n",
    "\n",
    "        :param Tensor embedded_inputs: Embedded inputs of Pointer-Net\n",
    "        :param Tensor decoder_input: First decoder's input\n",
    "        :param Tensor hidden: First decoder's hidden states\n",
    "        :param Tensor context: Encoder's outputs\n",
    "        :return: (Output probabilities, Pointers indices), last hidden state\n",
    "        \"\"\"\n",
    "        batch_size = embedded_inputs.size(0)\n",
    "        input_length = embedded_inputs.size(1)\n",
    "        assert (beam_size <= input_length-1) & (beam_size >= 1), f\"Current beam size is {beam_size} while input_length is {input_length}.\"\n",
    "\n",
    "        # (batch, seq_len)\n",
    "        mask = self.mask.repeat(input_length).unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "        # Generating arang(input_length), broadcasted across batch_size\n",
    "        runner = self.runner.repeat(input_length)\n",
    "        for i in range(input_length):\n",
    "            runner.data[i] = i\n",
    "        runner = runner.unsqueeze(0).expand(batch_size, -1).long()\n",
    "\n",
    "        # Initilize the first iteration of index, which is 0 since we want to start at that index\n",
    "        index0 = self.index0.repeat(batch_size)\n",
    "\n",
    "        def step(x, hidden, mask_step):\n",
    "            \"\"\"\n",
    "            Recurrence step function\n",
    "\n",
    "            :param Tensor x: Input at time t\n",
    "            :param tuple(Tensor, Tensor) hidden: Hidden states at time t-1\n",
    "            :return: Hidden states at time t (h, c), Attention probabilities (Alpha)\n",
    "            \"\"\"\n",
    "            # Regular LSTM\n",
    "            h, c = hidden\n",
    "\n",
    "            gates = self.input_to_hidden(x) + self.hidden_to_hidden(h)\n",
    "            input, forget, cell, out = gates.chunk(4, -1)\n",
    "\n",
    "            input = F.sigmoid(input)\n",
    "            forget = F.sigmoid(forget)\n",
    "            cell = F.tanh(cell)\n",
    "            out = F.sigmoid(out)\n",
    "\n",
    "            c_t = (forget * c) + (input * cell)\n",
    "            h_t = out * F.tanh(c_t)\n",
    "\n",
    "            # Attention section\n",
    "            hidden_t, output = self.att(h_t, context, torch.eq(mask_step, 0))\n",
    "            hidden_t = F.tanh(self.hidden_out(torch.cat((hidden_t, h_t), 1)))\n",
    "\n",
    "            return hidden_t, c_t, output\n",
    "\n",
    "        def masking(index, mask, runner):\n",
    "            one_hot_pointers = (runner == index.unsqueeze(1).expand(-1, input_length)).float()\n",
    "            # Update mask to ignore seen indices\n",
    "            mask = mask * (1 - one_hot_pointers)\n",
    "            # Get embedded inputs by max indices\n",
    "            embedding_mask = one_hot_pointers.unsqueeze(2).expand(-1, -1, self.embedding_dim).byte()\n",
    "            decoder_input = embedded_inputs[embedding_mask.data > 0].view(batch_size, self.embedding_dim)\n",
    "            return decoder_input, mask\n",
    "\n",
    "        outputs = []\n",
    "        pointers = []\n",
    "        decoder_input_list = []\n",
    "        mask_list = []\n",
    "\n",
    "        # 1st recurrent loop, the idea is to get the maximum probabilities and indices for each iteration \n",
    "        # Force the first iteration to take indice 0: \n",
    "            # Input: \n",
    "                # hidden states from the last step of the encoder (256, 512) x 2\n",
    "                # initialized decoder input (256, 128)\n",
    "            # Output: \n",
    "                # 1 decoder input for the next step (256, 128)\n",
    "                # 1 updated hidden state pair (256, 512) x 2\n",
    "                # 1 decoder output, softmax of the attention (256, 5)\n",
    "                # 1 pointer - index0 (256)\n",
    "        # At the second iteration (i.e. at sequence length index 1):\n",
    "            # Input: \n",
    "                # Updated hidden states from the last step of the decoder (256, 512) x 2\n",
    "                # pointed decoder input (256, 128)\n",
    "            # Output: \n",
    "                # <beam_size> decoder inputs for the next step (256, 128) x <beam_size>\n",
    "                # 1 updated hidden state pair (256, 512) x 2\n",
    "                # 1 decoder output, softmax of the attention (256, 5)\n",
    "                # <beam_size> pointers (256) x <beam_size>\n",
    "        for _ in range(2):\n",
    "            h_t, c_t, outs = step(decoder_input, hidden, mask_step = mask)\n",
    "            hidden = (h_t, c_t)\n",
    "            masked_outs = outs * mask # Masking selected inputs\n",
    "            \n",
    "            if _ == 0:\n",
    "                max_probs, indices = masked_outs.max(1)\n",
    "                # decoder_input, mask = masking(index = index0, mask = mask, runner = runner)\n",
    "                # Save the decoder output and pointer at the 1st step\n",
    "                outputs.append(outs.unsqueeze(0)) # -> (1, 256, 5)\n",
    "                pointers.append(index0.unsqueeze(1)) # -> (256, 1) ~ (beam, batch, seq_len)\n",
    "            \n",
    "            elif _ == 1:\n",
    "                max_probs, indices = torch.topk(masked_outs, k = beam_size, dim = 1, largest = True, sorted = False)\n",
    "                # Save the decoder output at the 2nd step\n",
    "                outputs.append(outs.unsqueeze(0)) # -> (1, 256, 5) x 2\n",
    "\n",
    "                for ind in indices.permute(1, 0): # (256) in (<beam_size>, 256)\n",
    "                    # Save the 2 pointers at the 2nd step\n",
    "                    pointers.append(ind.unsqueeze(1)) # -> (256, 1) x (1 + <beam_size>)\n",
    "                    decoder_input, mask_1_ = masking(index = ind, mask = mask, runner = runner)\n",
    "                    decoder_input_list.append(decoder_input) # -> (256, 128) x <beam_size>\n",
    "                    mask_list.append(mask_1_) # -> (256, 5) x <beam_size>\n",
    "        \n",
    "        # Concatenate everything from the 1st recurrent loop to torch tensor type, pay attention to the dimensions of the outputs and pointers\n",
    "        outputs = torch.cat(outputs, 0) # -> (2, 256, 5) dtype torch tensor\n",
    "        master_outputs = []\n",
    "        master_pointers = []\n",
    "\n",
    "        # 2nd recurrent loop, run through the remaining steps in the decoder\n",
    "        for de_inp, mask_, i in zip(decoder_input_list, mask_list, range(1, beam_size + 1)):\n",
    "            \n",
    "            # Assign hidden and input right here to keep them constant while switching beam\n",
    "            hidden_2_ = hidden\n",
    "            decoder_input_2_ = de_inp\n",
    "            mask_2_ = mask_\n",
    "            outputs_2_ = []\n",
    "            pointers_2_ = []\n",
    "            for _ in range(input_length - 2): # -2 refers to the initial loop, +2 refers to the length having one more token at the beginning, i.e. the <bos>\n",
    "                h_t, c_t, outs = step(decoder_input_2_, hidden_2_, mask_2_)\n",
    "                hidden_2_ = (h_t, c_t)\n",
    "                masked_outs = outs * mask_2_\n",
    "                max_probs, indices_2_ = masked_outs.max(1)\n",
    "                decoder_input_2_, mask_2_ = masking(index = indices_2_, mask = mask_2_, runner = runner)\n",
    "                # Save the current beam's decoder outputs and pointers to a dummy list\n",
    "                outputs_2_.append(outs.unsqueeze(0)) # -> (1, 256, 5) x (seq_len - 2 + 1)\n",
    "                pointers_2_.append(indices_2_.unsqueeze(1)) # -> (256, 1) x (seq_len - 2 + 1)\n",
    "\n",
    "            # Concatenate the current beam's decoder outputs and pointers to the master list\n",
    "            master_outputs.append(torch.cat(\n",
    "                [\n",
    "                    outputs, # (2, 256, 5)\n",
    "                    torch.cat(outputs_2_, 0) # -> (seq_len - 2 + 2, 256, 5)\n",
    "                ], 0\n",
    "            ).unsqueeze(0)) # -> (1, seq_len + 2, 256, 5) x <beam_size> torch tensors in list\n",
    "\n",
    "            master_pointers.append(torch.cat(\n",
    "                [\n",
    "                    pointers[0], pointers[i], # (256, 1) x 2\n",
    "                    torch.cat(pointers_2_, 1) # -> (256, seq_len - 2 + 2)\n",
    "                ], 1\n",
    "            ).unsqueeze(0)) # -> (1, 256, 5 + 2) x <beam_size> torch tensors in list\n",
    "        \n",
    "        # -> (<beam_size>, 256, 5, 5 + 2) dtype torch tensor ~ (beam, batch, seq_len as cond. probability, seq_len + 1)\n",
    "        master_outputs = torch.cat(master_outputs, 0).permute(0, 2, 3, 1)\n",
    "\n",
    "        # -> (<beam_size>, 256, 5 + 2) dtype torch tensor ~ (beam , batch, seq_len + 2)\n",
    "        master_pointers = torch.cat(master_pointers, 0)\n",
    "\n",
    "        return (master_outputs, master_pointers)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = torch.rand(256, 1)\n",
    "b = torch.rand(256, 3)\n",
    "a = torch.cat([a, a, b], 1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "u = torch.tensor(\n",
    "    [[3, 54, 6, 108, -9], \n",
    "    [7, 1100, 13, -99, 0],\n",
    "    [-99, -34, 13, 12, 55]]\n",
    ")\n",
    "p, index = torch.topk(u, k = 1, dim = 1, largest = True, sorted = False)\n",
    "p, p.shape, index, index.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for ind in index.permute(1, 0):\n",
    "    print(ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_o - torch.Size([256, 5, 5])\n",
      "pt - torch.Size([256, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2008, 0.2008, 0.2008, 0.2008, 0.2008],\n",
       "        [0.2001, 0.2001, 0.2001, 0.2001, 0.2001],\n",
       "        [0.1997, 0.1997, 0.1997, 0.1997, 0.1997],\n",
       "        [0.1996, 0.1996, 0.1996, 0.1996, 0.1996],\n",
       "        [0.1998, 0.1998, 0.1998, 0.1998, 0.1998]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(\n",
    "    embedding_dim = 128,\n",
    "    hidden_dim = 512\n",
    ")\n",
    "\n",
    "decoder_hidden0 = (en_h[-1].squeeze(0), en_c[-1].squeeze(0))\n",
    "\n",
    "(de_o, pt) = decoder(\n",
    "    embedded_inputs = x_embed,\n",
    "    decoder_input = torch.rand(256, 128),\n",
    "    hidden = decoder_hidden0,\n",
    "    context = en_o.permute(1, 0, 2),\n",
    "    beam_size = 1\n",
    ")\n",
    "\n",
    "de_o = de_o.squeeze(0)\n",
    "pt = pt.squeeze(0)\n",
    "\n",
    "print('de_o -', de_o.shape)\n",
    "print('pt -', pt.shape)\n",
    "\n",
    "de_o[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(4):\n",
    "    print(i, de_o[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "x_0 & x_1 & x_2 & x_3 & x_4 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{iter 0 : } P\\left( x_2|\\theta \\right) = \\frac{\\exp{x_2}}{\\sum_{i=0}^{5}\\exp{x_i}}\n",
    "$$\n",
    "$$\n",
    "\\text{iter 1 : } P\\left( x_4|x_2, \\theta \\right) = \\frac{\\exp{x_4}}{\\sum_{i=0}^{{0, 1, 3, 4}}\\exp{x_i}}\n",
    "$$\n",
    "$$\n",
    "\\text{iter 2 : } P\\left( x_3|x_2,x_4, \\theta \\right) = \\frac{\\exp{x_3}}{\\sum_{i=0}^{{0, 1, 3}}\\exp{x_i}}\n",
    "$$\n",
    "$$\n",
    "\\text{iter 3 : } P\\left( x_1|x_2,x_3,x_4, \\theta \\right) = \\frac{\\exp{x_3}}{\\sum_{i=0}^{{0, 1}}\\exp{x_i}}\n",
    "$$\n",
    "$$\n",
    "\\text{iter 4 : } P\\left( x_0|x_1,x_2,x_3,x_4, \\theta \\right) = \\frac{\\exp{x_0}}{\\sum_{i=0}^{{0}}\\exp{x_i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointerNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Pointer-Net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, embedding_dim,\n",
    "        hidden_dim,\n",
    "        lstm_layers,\n",
    "        dropout,\n",
    "        bidir = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initiate Pointer-Net\n",
    "\n",
    "        :param int embedding_dim: Number of embbeding channels\n",
    "        :param int hidden_dim: Encoders hidden units\n",
    "        :param int lstm_layers: Number of layers for LSTMs\n",
    "        :param float dropout: Float between 0-1\n",
    "        :param bool bidir: Bidirectional\n",
    "        \"\"\"\n",
    "\n",
    "        super(PointerNet, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.bidir = bidir\n",
    "        self.embedding = nn.Linear(2, embedding_dim)\n",
    "        self.encoder = Encoder(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            lstm_layers,\n",
    "            dropout,\n",
    "            bidir\n",
    "        )\n",
    "        self.decoder = Decoder(embedding_dim, hidden_dim)\n",
    "        self.decoder_input0 = Parameter(torch.FloatTensor(embedding_dim), requires_grad=False)\n",
    "\n",
    "        # Initialize decoder_input0\n",
    "        nn.init.uniform_(self.decoder_input0, -1, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        PointerNet - Forward-pass\n",
    "\n",
    "        :param Tensor inputs: Input sequence\n",
    "        :return: Pointers probabilities and indices\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = inputs.size(0)\n",
    "        input_length = inputs.size(1)\n",
    "\n",
    "        decoder_input0 = self.decoder_input0.unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "        inputs = inputs.view(batch_size * input_length, -1)\n",
    "        embedded_inputs = self.embedding(inputs).view(batch_size, input_length, -1)\n",
    "\n",
    "        encoder_hidden0 = self.encoder.init_hidden(embedded_inputs)\n",
    "        encoder_outputs, encoder_hidden = self.encoder(embedded_inputs, encoder_hidden0)\n",
    "        \n",
    "        if self.bidir:\n",
    "            decoder_hidden0 = (encoder_hidden[0][-1].squeeze(0), encoder_hidden[1][-1].squeeze(0))\n",
    "        else:\n",
    "            decoder_hidden0 = (encoder_hidden[0][-1], encoder_hidden[1][-1])\n",
    "        \n",
    "        (outputs, pointers) = self.decoder(\n",
    "            embedded_inputs,\n",
    "            decoder_input0,\n",
    "            decoder_hidden0,\n",
    "            encoder_outputs.permute(1, 0, 2),\n",
    "            beam_size = 1\n",
    "        )\n",
    "\n",
    "        return  outputs, pointers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NLLLoss = torch.nn.NLLLoss(reduction = 'mean')\n",
    "a = nn.LogSoftmax(dim = 1)(torch.rand(256, 5, 5))\n",
    "b = torch.randint(0, 5, (256, 5)).type(torch.LongTensor)\n",
    "NLLLoss(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len dataset - 100000\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load(r\"C://Users//PHAM DUY//python projects//d2l//data//100K_train_5.pt\")\n",
    "print('len dataset -', len(dataset))\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = params.batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Points': tensor([[0.3157, 0.1738],\n",
       "         [0.4446, 0.9743],\n",
       "         [0.2807, 0.3822],\n",
       "         [0.2848, 0.8318],\n",
       "         [0.0605, 0.2040]]),\n",
       " 'Solution': tensor([0, 2, 1, 3, 4])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4830)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss(reduction = 'mean')(\n",
    "    torch.rand(256, 5, 5).type(torch.float32),\n",
    "    torch.randint(0, 5, (256, 5)).type(torch.int64)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = PointerNet(\n",
    "    params.embedding_size,\n",
    "    params.hidden_size,\n",
    "    params.nof_lstms,\n",
    "    params.dropout,\n",
    "    params.bidir\n",
    ")\n",
    "\n",
    "if params.gpu and torch.cuda.is_available():\n",
    "    USE_CUDA = True\n",
    "    print('Using GPU, %i devices.' % torch.cuda.device_count())\n",
    "else:\n",
    "    USE_CUDA = False\n",
    "\n",
    "if USE_CUDA:\n",
    "    model.cuda()\n",
    "    net = torch.nn.DataParallel(model, device_ids = range(torch.cuda.device_count()))\n",
    "\n",
    "NLLLoss = torch.nn.NLLLoss(reduction = 'mean')\n",
    "model_optim = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr = params.lr\n",
    ")\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(params.nof_epoch):\n",
    "    batch_loss = []\n",
    "    iterator = tqdm(dataloader, unit = 'Batch')\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(iterator):\n",
    "        iterator.set_description('Epoch %i/%i' % (epoch+1, params.nof_epoch))\n",
    "\n",
    "        train_batch = Variable(sample_batched['Points'])\n",
    "        target_batch = Variable(sample_batched['Solution'])\n",
    "\n",
    "        if USE_CUDA:\n",
    "            train_batch = train_batch.cuda()\n",
    "            target_batch = target_batch.type(torch.LongTensor).cuda()\n",
    "\n",
    "        o, p = model(train_batch)\n",
    "        o = torch.log(o.squeeze(0))[:,:,:-2]\n",
    "        p = p.squeeze(0)\n",
    "        # print('o shape -', o.shape)\n",
    "        # print('o dtype -', o.dtype)\n",
    "        # print('o[:20] -', o[:5])\n",
    "        # print('p[:20] -', p[:5])\n",
    "        # print('target_batch[:20] -', target_batch[:20])\n",
    "        # print(o.get_device())\n",
    "\n",
    "        # print('target_batch shape -', target_batch.shape)\n",
    "        # print('target_batch dtype -', target_batch.dtype)\n",
    "        # print('target_batch[:20] -', target_batch[:5])\n",
    "        # print(target_batch.get_device())\n",
    "\n",
    "        # loss = -torch.log(o.max(dim = 1)[0]).sum(dim = 1).mean(dim = 0)\n",
    "        loss = NLLLoss(o, target_batch)\n",
    "        loss = loss.contiguous().type(torch.float32)\n",
    "        # print('loss dtype -', loss.dtype)\n",
    "        # print('loss shape -', loss.shape)\n",
    "        # print('loss -', loss)\n",
    "        # print(p[0], target_batch[0])\n",
    "        losses.append(loss)\n",
    "        batch_loss.append(loss.reshape(1))\n",
    "\n",
    "        model_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "\n",
    "        iterator.set_postfix(loss = '{}'.format(loss))\n",
    "\n",
    "    iterator.set_postfix(loss = np.average(torch.cat(batch_loss, 0).cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_test = TSPDataset(\n",
    "    params.test_size,\n",
    "    params.nof_points\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size = params.test_size,\n",
    "    shuffle = False,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "iterator = tqdm(dataloader_test, unit = 'Batch')\n",
    "\n",
    "for i_batch, sample_batched in enumerate(iterator):\n",
    "\n",
    "    X_test = Variable(sample_batched['Points'])\n",
    "    y_test = Variable(sample_batched['Solution'])\n",
    "\n",
    "    if USE_CUDA:\n",
    "        X_test = X_test.cuda()\n",
    "        y_test = y_test.type(torch.LongTensor).cuda()\n",
    "\n",
    "    y_pred, p_test = model(X_test)\n",
    "    p_test = p_test.squeeze(0)[:,:-2]\n",
    "    y_pred = y_pred.contiguous().type(torch.float32)\n",
    "\n",
    "    print(p_test[0], y_test[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for p, y in zip(p_test[:50], y_test[:50]):\n",
    "    print(p, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_test = TSPDataset(\n",
    "    params.test_size,\n",
    "    10\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size = params.test_size,\n",
    "    shuffle = False,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "iterator = tqdm(dataloader_test, unit = 'Batch')\n",
    "\n",
    "for i_batch, sample_batched in enumerate(iterator):\n",
    "\n",
    "    X_test = Variable(sample_batched['Points'])\n",
    "    y_test = Variable(sample_batched['Solution'])\n",
    "\n",
    "    if USE_CUDA:\n",
    "        X_test = X_test.cuda()\n",
    "        y_test = y_test.type(torch.LongTensor).cuda()\n",
    "\n",
    "    y_pred, p_test = model(X_test)\n",
    "    p_test = p_test.squeeze(0)[:,:-2]\n",
    "    y_pred = y_pred.contiguous().type(torch.float32)\n",
    "\n",
    "    print(p_test[0], y_test[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for p, y in zip(p_test[:20], y_test[:20]):\n",
    "    print(p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
